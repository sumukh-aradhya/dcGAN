{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ad9j3bdoAki0"
      },
      "outputs": [],
      "source": [
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "YjCMbjhHAsbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive/Sem2/Topics_in_ML/Project/\""
      ],
      "metadata": {
        "id": "ILQizYyFAubr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    print(\"TensorFlow will run on GPU.\")\n",
        "else:\n",
        "    print(\"TensorFlow will run on CPU.\")\n",
        "\n",
        "tf.config.optimizer.set_experimental_options({\n",
        "    \"disable_meta_optimizer\": True\n",
        "})\n",
        "\n",
        "print(\"#################################\")\n",
        "\n",
        "import h5py\n",
        "import numpy as np\n",
        "from tensorflow.keras import utils\n",
        "with h5py.File('/content/drive/My Drive/Sem2/Topics_in_ML/Project/Galaxy10_DECals1.h5', 'r') as F:\n",
        "    images = np.array(F['images'])\n",
        "    labels = np.array(F['ans'])\n",
        "labels = utils.to_categorical(labels, 10)\n",
        "labels = labels.astype(np.float32)\n",
        "images = images.astype(np.float32)\n",
        "print(\"Cell 1 Done\")\n",
        "\n",
        "print(\"#################################\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_idx, test_idx = train_test_split(np.arange(labels.shape[0]), test_size=0.1)\n",
        "train_images, train_labels, test_images, test_labels = images[train_idx], labels[train_idx], images[test_idx], labels[test_idx]\n",
        "def preprocess(img):\n",
        "    img = tf.image.resize(img, [64, 64])\n",
        "    img = (tf.cast(img, \"float32\") - 127.5) / 127.5\n",
        "    return img\n",
        "\n",
        "\n",
        "train_images = np.array([preprocess(img) for img in train_images])\n",
        "print(\"Cell 2 Done\")\n",
        "\n",
        "print(\"#################################\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def sample_batch(images, batch_size=1):\n",
        "    indices = np.random.choice(images.shape[0], batch_size, replace=False)\n",
        "    return images[indices]\n",
        "def display(images, n=10, size=(20, 20), cmap=None, as_type=None, save_to=None):\n",
        "    plt.figure(figsize=size)\n",
        "    for i in range(min(n, images.shape[0])):\n",
        "        plt.subplot(1, n, i + 1)\n",
        "        img = images[i]\n",
        "        if as_type:\n",
        "            img = img.astype(as_type)\n",
        "        if img.max() > 1.0:\n",
        "            img = img / 255.0\n",
        "        plt.imshow(img, cmap=cmap)\n",
        "        plt.axis(\"off\")\n",
        "    if save_to:\n",
        "        plt.savefig(save_to)\n",
        "        print(f\"\\nSaved to {save_to}\")\n",
        "    plt.show()\n",
        "print(\"Cell 3 done\")\n",
        "\n",
        "print(\"#################################\")\n",
        "\n",
        "train_sample = sample_batch(train_images)\n",
        "from keras import (layers, models, callbacks, losses, utils, metrics, optimizers)\n",
        "IMAGE_SIZE = 64\n",
        "CHANNELS = 3\n",
        "BATCH_SIZE = 64\n",
        "Z_DIM = 100\n",
        "EPOCHS = 200\n",
        "LOAD_MODEL = False\n",
        "ADAM_BETA_1 = 0.5\n",
        "ADAM_BETA_2 = 0.999\n",
        "LEARNING_RATE = 0.0001\n",
        "NOISE_PARAM = 0.5\n",
        "print(\"Cell 4 done\")\n",
        "\n",
        "print(\"#################################\")\n",
        "\n",
        "discriminator_input = layers.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, CHANNELS))\n",
        "x = layers.Conv2D(64, kernel_size=4, strides=1, padding=\"same\", use_bias=False)(\n",
        "    discriminator_input\n",
        ")\n",
        "x = layers.LeakyReLU(0.2)(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Conv2D(\n",
        "    128, kernel_size=4, strides=1, padding=\"same\", use_bias=False\n",
        ")(x)\n",
        "x = layers.BatchNormalization(momentum=0.9)(x)\n",
        "x = layers.LeakyReLU(0.2)(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Conv2D(\n",
        "    256, kernel_size=4, strides=1, padding=\"same\", use_bias=False\n",
        ")(x)\n",
        "x = layers.BatchNormalization(momentum=0.9)(x)\n",
        "x = layers.LeakyReLU(0.2)(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Conv2D(\n",
        "    512, kernel_size=4, strides=1, padding=\"same\", use_bias=False\n",
        ")(x)\n",
        "x = layers.BatchNormalization(momentum=0.9)(x)\n",
        "x = layers.LeakyReLU(0.2)(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Conv2D(\n",
        "    1024, kernel_size=4, strides=1, padding=\"same\", use_bias=False\n",
        ")(x)\n",
        "x = layers.BatchNormalization(momentum=0.9)(x)\n",
        "x = layers.LeakyReLU(0.2)(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Conv2D(\n",
        "    1,\n",
        "    kernel_size=4,\n",
        "    strides=1,\n",
        "    padding=\"valid\",\n",
        "    use_bias=False,\n",
        "    activation=\"sigmoid\",\n",
        ")(x)\n",
        "discriminator_output = layers.Flatten()(x)\n",
        "discriminator = models.Model(discriminator_input, discriminator_output)\n",
        "discriminator.summary()\n",
        "\n",
        "print(\"#################################\")\n",
        "\n",
        "# generator_input = layers.Input(shape=(Z_DIM,))\n",
        "# #x = layers.Reshape((1, 1, Z_DIM))(generator_input)\n",
        "# x = layers.Dense(2*2*1024, use_bias=False)(generator_input)\n",
        "# x = layers.Reshape((2, 2, 1024))(x)\n",
        "# x = layers.BatchNormalization()(x)\n",
        "# x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "# x = layers.Conv2DTranspose(\n",
        "#     1024, kernel_size=4, strides=1, padding=\"same\", use_bias=False\n",
        "# )(x)\n",
        "# x = layers.BatchNormalization(momentum=0.9)(x)\n",
        "# x = layers.LeakyReLU(0.2)(x)\n",
        "# x = layers.Conv2DTranspose(\n",
        "#     512, kernel_size=4, strides=1, padding=\"same\", use_bias=False\n",
        "# )(x)\n",
        "# x = layers.BatchNormalization(momentum=0.9)(x)\n",
        "# x = layers.LeakyReLU(0.2)(x)\n",
        "# x = layers.Conv2DTranspose(\n",
        "#     256, kernel_size=4, strides=1, padding=\"same\", use_bias=False\n",
        "# )(x)\n",
        "# x = layers.BatchNormalization(momentum=0.9)(x)\n",
        "# x = layers.LeakyReLU(0.2)(x)\n",
        "# x = layers.Conv2DTranspose(\n",
        "#     128, kernel_size=4, strides=1, padding=\"same\", use_bias=False\n",
        "# )(x)\n",
        "# x = layers.BatchNormalization(momentum=0.9)(x)\n",
        "# x = layers.LeakyReLU(0.2)(x)\n",
        "# x = layers.Conv2DTranspose(\n",
        "#     64, kernel_size=4, strides=1, padding=\"same\", use_bias=False\n",
        "# )(x)\n",
        "# x = layers.BatchNormalization(momentum=0.9)(x)\n",
        "# x = layers.LeakyReLU(0.2)(x)\n",
        "# generator_output = layers.Conv2DTranspose(\n",
        "#     CHANNELS,\n",
        "#     kernel_size=4,\n",
        "#     strides=1,\n",
        "#     padding=\"same\",\n",
        "#     use_bias=False,\n",
        "#     activation=\"tanh\",\n",
        "# )(x)\n",
        "# generator = models.Model(generator_input, generator_output)\n",
        "# generator.summary()\n",
        "\n",
        "generator_input = layers.Input(shape=(Z_DIM,))\n",
        "x = layers.Dense(2*2*1024, use_bias=False)(generator_input)  # Start from a 2x2 feature map\n",
        "x = layers.Reshape((2, 2, 1024))(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "# Increasing strides to upscale the feature map\n",
        "x = layers.Conv2DTranspose(1024, kernel_size=4, strides=2, padding=\"same\", use_bias=False)(x)  # 4x4\n",
        "x = layers.BatchNormalization(momentum=0.9)(x)\n",
        "x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "x = layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\", use_bias=False)(x)  # 8x8\n",
        "x = layers.BatchNormalization(momentum=0.9)(x)\n",
        "x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "x = layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\", use_bias=False)(x)  # 16x16\n",
        "x = layers.BatchNormalization(momentum=0.9)(x)\n",
        "x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "x = layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\", use_bias=False)(x)  # 32x32\n",
        "x = layers.BatchNormalization(momentum=0.9)(x)\n",
        "x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "x = layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding=\"same\", use_bias=False)(x)  # 64x64\n",
        "x = layers.BatchNormalization(momentum=0.9)(x)\n",
        "x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "generator_output = layers.Conv2DTranspose(CHANNELS, kernel_size=4, strides=1, padding=\"same\", use_bias=False, activation=\"tanh\")(x)\n",
        "generator = models.Model(generator_input, generator_output)\n",
        "generator.summary()\n",
        "\n",
        "print(\"#################################\")\n",
        "\n",
        "class DCGAN(models.Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super(DCGAN, self).__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer):\n",
        "        super(DCGAN, self).compile()\n",
        "        self.loss_fn = losses.BinaryCrossentropy()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.d_loss_metric = metrics.Mean(name=\"d_loss\")\n",
        "        self.d_real_acc_metric = metrics.BinaryAccuracy(name=\"d_real_acc\")\n",
        "        self.d_fake_acc_metric = metrics.BinaryAccuracy(name=\"d_fake_acc\")\n",
        "        self.d_acc_metric = metrics.BinaryAccuracy(name=\"d_acc\")\n",
        "        self.g_loss_metric = metrics.Mean(name=\"g_loss\")\n",
        "        self.g_acc_metric = metrics.BinaryAccuracy(name=\"g_acc\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.d_loss_metric,\n",
        "            self.d_real_acc_metric,\n",
        "            self.d_fake_acc_metric,\n",
        "            self.d_acc_metric,\n",
        "            self.g_loss_metric,\n",
        "            self.g_acc_metric,\n",
        "        ]\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "        random_latent_vectors = tf.random.normal(\n",
        "            shape=(batch_size, self.latent_dim)\n",
        "        )\n",
        "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "            generated_images = self.generator(\n",
        "                random_latent_vectors, training=True\n",
        "            )\n",
        "            real_predictions = self.discriminator(real_images, training=True)\n",
        "            fake_predictions = self.discriminator(\n",
        "                generated_images, training=True\n",
        "            )\n",
        "\n",
        "            real_labels = tf.ones_like(real_predictions)\n",
        "            real_noisy_labels = real_labels + NOISE_PARAM * tf.random.uniform(\n",
        "                tf.shape(real_predictions)\n",
        "            )\n",
        "            fake_labels = tf.zeros_like(fake_predictions)\n",
        "            fake_noisy_labels = fake_labels - NOISE_PARAM * tf.random.uniform(\n",
        "                tf.shape(fake_predictions)\n",
        "            )\n",
        "\n",
        "            d_real_loss = self.loss_fn(real_noisy_labels, real_predictions)\n",
        "            d_fake_loss = self.loss_fn(fake_noisy_labels, fake_predictions)\n",
        "            d_loss = (d_real_loss + d_fake_loss) / 2.0\n",
        "\n",
        "            g_loss = self.loss_fn(real_labels, fake_predictions)\n",
        "\n",
        "        gradients_of_discriminator = disc_tape.gradient(\n",
        "            d_loss, self.discriminator.trainable_variables\n",
        "        )\n",
        "        gradients_of_generator = gen_tape.gradient(\n",
        "            g_loss, self.generator.trainable_variables\n",
        "        )\n",
        "\n",
        "        self.d_optimizer.apply_gradients(\n",
        "            zip(gradients_of_discriminator, discriminator.trainable_variables)\n",
        "        )\n",
        "        self.g_optimizer.apply_gradients(\n",
        "            zip(gradients_of_generator, generator.trainable_variables)\n",
        "        )\n",
        "\n",
        "        self.d_loss_metric.update_state(d_loss)\n",
        "        self.d_real_acc_metric.update_state(real_labels, real_predictions)\n",
        "        self.d_fake_acc_metric.update_state(fake_labels, fake_predictions)\n",
        "        self.d_acc_metric.update_state(\n",
        "            [real_labels, fake_labels], [real_predictions, fake_predictions]\n",
        "        )\n",
        "        self.g_loss_metric.update_state(g_loss)\n",
        "        self.g_acc_metric.update_state(real_labels, fake_predictions)\n",
        "\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "print(\"Cell 5 Done\")\n",
        "\n",
        "print(\"#################################\")\n",
        "\n",
        "class ImageGenerator(callbacks.Callback):\n",
        "    def __init__(self, num_img, latent_dim):\n",
        "        self.num_img = num_img\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        random_latent_vectors = tf.random.normal(\n",
        "            shape=(self.num_img, self.latent_dim)\n",
        "        )\n",
        "        generated_images = self.model.generator(random_latent_vectors)\n",
        "        generated_images = generated_images * 127.5 + 127.5\n",
        "        generated_images = generated_images.numpy()\n",
        "        display(\n",
        "            generated_images,\n",
        "        )\n",
        "print(\"Cell 6 Done\")\n",
        "\n",
        "print(\"#################################\")\n",
        "\n",
        "dcgan = DCGAN(discriminator=discriminator, generator=generator, latent_dim=Z_DIM)\n",
        "if LOAD_MODEL:\n",
        "    dcgan.load_weights(\"/content/drive/My Drive/Sem2/Topics_in_ML/Project/checkpoint/checkpoint.ckpt\")\n",
        "\n",
        "dcgan.compile(\n",
        "    d_optimizer=optimizers.Adam(\n",
        "        learning_rate=LEARNING_RATE, beta_1=ADAM_BETA_1, beta_2=ADAM_BETA_2\n",
        "    ),\n",
        "    g_optimizer=optimizers.Adam(\n",
        "        learning_rate=LEARNING_RATE, beta_1=ADAM_BETA_1, beta_2=ADAM_BETA_2\n",
        "    ),\n",
        ")\n",
        "print(\"Running model.fit\")\n",
        "\n",
        "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
        "    filepath=\"/content/drive/My Drive/Sem2/Topics_in_ML/Project/checkpoint/checkpoint.weights.h5\",\n",
        "    save_weights_only=True,\n",
        "    save_freq=\"epoch\",\n",
        "    verbose=0,\n",
        ")\n",
        "tensorboard_callback = callbacks.TensorBoard(log_dir=\"logs\")\n",
        "class ImageGenerator(callbacks.Callback):\n",
        "    def __init__(self, num_img, latent_dim):\n",
        "        self.num_img = num_img\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        random_latent_vectors = tf.random.normal(\n",
        "            shape=(self.num_img, self.latent_dim)\n",
        "        )\n",
        "        generated_images = self.model.generator(random_latent_vectors)\n",
        "        generated_images = generated_images * 127.5 + 127.5\n",
        "        generated_images = generated_images.numpy()\n",
        "        display(\n",
        "            generated_images,\n",
        "            #save_to=\"/content/drive/My Drive/Sem2/Topics_in_ML/Project/output/Day3/generated_img_%03d.png\" % (epoch),\n",
        "        )\n",
        "\n",
        "dcgan.fit(\n",
        "    train_images,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[\n",
        "        model_checkpoint_callback,\n",
        "        tensorboard_callback,\n",
        "        #ImageGenerator(num_img=10, latent_dim=Z_DIM),\n",
        "    ],\n",
        ")\n",
        "print(\"Cell 7 Done\")\n",
        "\n",
        "print(\"#################################\")\n",
        "\n",
        "print(\"Saving models\")\n",
        "generator.save(\"/content/drive/My Drive/Sem2/Topics_in_ML/Project/models/generator\")\n",
        "discriminator.save(\"/content/drive/My Drive/Sem2/Topics_in_ML/Project/models/discriminator\")\n",
        "\n",
        "print(\"All tasks completed successfully!\")\n",
        "print(\"#################################\")"
      ],
      "metadata": {
        "id": "22o7kCS3AwED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_width, grid_height = (10, 3)\n",
        "z_sample = np.random.normal(size=(grid_width * grid_height, Z_DIM))"
      ],
      "metadata": {
        "id": "zUENENnsAzAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reconstructions = generator.predict(z_sample)"
      ],
      "metadata": {
        "id": "GrcKIk8RA0kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(18, 5))\n",
        "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "\n",
        "for i in range(grid_width * grid_height):\n",
        "    ax = fig.add_subplot(grid_height, grid_width, i + 1)\n",
        "    ax.axis(\"off\")\n",
        "    ax.imshow(reconstructions[i, :, :], cmap=\"Greys\")"
      ],
      "metadata": {
        "id": "E55TT_rBA2ER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_images(img1, img2):\n",
        "    return np.mean(np.abs(img1 - img2))"
      ],
      "metadata": {
        "id": "u4nJCoEqA3SF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r, c = 3, 5\n",
        "fig, axs = plt.subplots(r, c, figsize=(10, 6))\n",
        "fig.suptitle(\"Generated images\", fontsize=20)\n",
        "\n",
        "noise = np.random.normal(size=(r * c, Z_DIM))\n",
        "gen_imgs = generator.predict(noise)\n",
        "\n",
        "cnt = 0\n",
        "for i in range(r):\n",
        "    for j in range(c):\n",
        "        axs[i, j].imshow(gen_imgs[cnt], cmap=\"gray_r\")\n",
        "        axs[i, j].axis(\"off\")\n",
        "        cnt += 1\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "93rM_B1xA6ZB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}